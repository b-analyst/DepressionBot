{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "depression_bot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9fcfce950f246f593a85249c651e883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0e0a88cac084482b2b6b2031afa4b9f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da823fe1262048e887bf9da6cd33fa83",
              "IPY_MODEL_5b321fffc5334dddbcd21b9470c64888"
            ]
          }
        },
        "a0e0a88cac084482b2b6b2031afa4b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da823fe1262048e887bf9da6cd33fa83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7fbe2e95d3de48118febb2167d0cd0fc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a14279f173044dc9b7992df8a7ea2ef"
          }
        },
        "5b321fffc5334dddbcd21b9470c64888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_38d170a30c094fb39656243f2ca6fe7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:03&lt;00:00, 300kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_820153d5ea0f4f2c94a2d4ab84c3d56d"
          }
        },
        "7fbe2e95d3de48118febb2167d0cd0fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a14279f173044dc9b7992df8a7ea2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "38d170a30c094fb39656243f2ca6fe7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "820153d5ea0f4f2c94a2d4ab84c3d56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f92152b9b734fb8836ff598d0e60955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3a083270a9464671999402f2a912792d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eaf7aa7427f6481397e2047eb0f59134",
              "IPY_MODEL_e65fa8512d214550905a1f3e9b53d56c"
            ]
          }
        },
        "3a083270a9464671999402f2a912792d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eaf7aa7427f6481397e2047eb0f59134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_802a059e1afb4de7a0b340e8b7113b05",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c74e4862676f47a7a1107e26990b421c"
          }
        },
        "e65fa8512d214550905a1f3e9b53d56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8362dfde0ba64ae5814314e7e2071c3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:02&lt;00:00, 206kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0441fa4d7ad24067a05fafa31c4faa70"
          }
        },
        "802a059e1afb4de7a0b340e8b7113b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c74e4862676f47a7a1107e26990b421c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8362dfde0ba64ae5814314e7e2071c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0441fa4d7ad24067a05fafa31c4faa70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acfbf4b539e74ea7817db96e3ff2933c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_904d584a2aaf4b9e926f5378e500dbcb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec364af0eb7d49a6b5a3a2e7fab5e46e",
              "IPY_MODEL_ea2c88f73f7541519a2af6e76d21c985"
            ]
          }
        },
        "904d584a2aaf4b9e926f5378e500dbcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec364af0eb7d49a6b5a3a2e7fab5e46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5d6463870d344a3962bb47bef22bd71",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c423c93bc4bf487599c4867fa383f881"
          }
        },
        "ea2c88f73f7541519a2af6e76d21c985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_943c15f53eb84118a6d729135611dd1f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.46MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7dc9757b35724cbe84b78069976049ff"
          }
        },
        "e5d6463870d344a3962bb47bef22bd71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c423c93bc4bf487599c4867fa383f881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "943c15f53eb84118a6d729135611dd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7dc9757b35724cbe84b78069976049ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e260c312835a4e81a367e942523b43d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6e25d9d15d546d0a308e7869f843dff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e82b6ff57b147c882739c1ad880a62d",
              "IPY_MODEL_ed516e174d54424898bf867f08224ee4"
            ]
          }
        },
        "f6e25d9d15d546d0a308e7869f843dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e82b6ff57b147c882739c1ad880a62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db8480b20f8a478b82e24e0c0e0ee757",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_677c1cf847ef481b91d2cec2528d46d6"
          }
        },
        "ed516e174d54424898bf867f08224ee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_689678ee6f174b5987a99c58044956c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 8.35kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9c95767980746aab5657f0ef52dfa14"
          }
        },
        "db8480b20f8a478b82e24e0c0e0ee757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "677c1cf847ef481b91d2cec2528d46d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "689678ee6f174b5987a99c58044956c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9c95767980746aab5657f0ef52dfa14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZX4HTx-EIOY",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9b1c77a5-00f1-4e84-f383-d3b5ec7818ed"
      },
      "source": [
        "from google.colab import files\n",
        "f = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-40c4d419-62e6-4e0e-a5d3-224c239586b7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-40c4d419-62e6-4e0e-a5d3-224c239586b7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving mentalillness.csv to mentalillness.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIezt3GtHxSG",
        "outputId": "24e04f8b-3c8d-4c1f-e9aa-f81b96f9302d"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-so5ge97x\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-so5ge97x\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 56.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (4.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.9.0.dev0) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.9.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.0.dev0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.9.0.dev0) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.9.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.9.0.dev0) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.9.0.dev0) (3.7.4.3)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.9.0.dev0-cp37-none-any.whl size=2584400 sha256=ec5b70f37050cb1fc0fd9c74c9e63d4b2b33ed9d80820f31a621bb226f1765f9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-udsqzhlm/wheels/70/d3/52/b3fa4f8b8ef04167ac62e5bb2accb62ae764db2a378247490e\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, sacremoses, huggingface-hub, tokenizers, transformers\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.0.dev0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD4tcos7270P",
        "outputId": "76184b63-bdee-4282-a2f9-cf8af1a2ae48"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 78470, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 78470 (delta 57), reused 107 (delta 44), pack-reused 78335\u001b[K\n",
            "Receiving objects: 100% (78470/78470), 61.29 MiB | 31.14 MiB/s, done.\n",
            "Resolving deltas: 100% (56027/56027), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV204GF6E0qr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77dc724b-a594-4cef-832e-3326fa687dc9"
      },
      "source": [
        "#!pip install --upgrade -q transformers tokenizers\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
        "from transformers import pipeline\n",
        "from tokenizers import Tokenizer\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import re\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "  print('Device name:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print('No GPU available, using the CPU instead.')\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5U5I_fhcENm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e033d41-8d3e-4bed-9a40-33e7afbfb7c9"
      },
      "source": [
        "df = pd.read_csv('/content/mentalillness.csv')\n",
        "df = df['0']\n",
        "df = df.astype(str).apply(lambda x: x.encode('ascii', 'ignore').decode('ascii'))\n",
        "df = df.replace('\\n','', regex=True)\n",
        "df = df.replace('nan','', regex=True)\n",
        "df.head()\n",
        "#df = df.set_index('label')\n",
        "#df = df.drop([1,2,3,4,5])\n",
        "\n",
        "#df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    I feel this way most days and I'm getting sick...\n",
              "1             Saw this today and wanted to share it.  \n",
              "2    I can understand if my situation was a permane...\n",
              "3    So suicidal thoughts are really common to me b...\n",
              "4    If any wants to share their experience.I read ...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViTvzHx8XhpR"
      },
      "source": [
        "df = df.dropna(axis=0, how='any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXIURQgGXr4N",
        "outputId": "acb8d085-b45f-4fb2-bec3-3b9de25662c1"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okldMZgagc2H"
      },
      "source": [
        "temp = []\n",
        "for line in df:\n",
        "  web_address = re.compile(r\"(?i)http(s):\\/\\/[a-z0-9.~_\\-\\/]+\")\n",
        "  line = web_address.sub('', line)\n",
        "  temp.append(line)\n",
        "\n",
        "df = temp\n",
        "\n",
        "df = pd.DataFrame(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Cxy6zRrEiG0Y",
        "outputId": "627c7034-444b-4c59-cd55-7df414a8c649"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I feel this way most days and I'm getting sick...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Saw this today and wanted to share it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I can understand if my situation was a permane...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So suicidal thoughts are really common to me b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If any wants to share their experience.I read ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0  I feel this way most days and I'm getting sick...\n",
              "1           Saw this today and wanted to share it.  \n",
              "2  I can understand if my situation was a permane...\n",
              "3  So suicidal thoughts are really common to me b...\n",
              "4  If any wants to share their experience.I read ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEebaghTegjU"
      },
      "source": [
        "train, test = train_test_split(\n",
        "    df,\n",
        "    test_size = 0.1,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKbsmS2ZiRiD",
        "outputId": "34a84e53-71da-4f8e-e9d3-b3a09c9ed8a1"
      },
      "source": [
        "test[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5305     I feel like my brain  is going to explode. I'm...\n",
              "24227                                                     \n",
              "25954                                                     \n",
              "66       The other day it was my birthday turned 27. I ...\n",
              "38       I've had 3 bouts of depression and anxiety, 1 ...\n",
              "                               ...                        \n",
              "4010               i'm so glad that little voice spoke up \n",
              "2904     :grin:(Alright, Mod's, kick it where ever ye f...\n",
              "20033    Until I was a late teen I had this sense that ...\n",
              "9631     Yesterday was bad. I sometimes have these epis...\n",
              "25       I'm depressed and sleep deprived. I'm growing ...\n",
              "Name: 0, Length: 2775, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXAir7_iIeoB"
      },
      "source": [
        "with open('train.txt', 'w') as f:\n",
        "  for line in train[0]:\n",
        "    line = '<|startoftext|>' + line + '<|endoftext|>'\n",
        "    f.write(line + '\\n')\n",
        "  f.close()\n",
        "\n",
        "with open('test.txt', 'w') as f:\n",
        "  for line in test[0]:\n",
        "    line = '<|startoftext|>' + line + '<|endoftext|>'\n",
        "    f.write(line + '\\n')\n",
        "  f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UBdFpLfCJNCk",
        "outputId": "ca7156cc-4d10-474b-d9c0-58ae4406e6e7"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/transformers/examples/pytorch/\")\n",
        "os.chdir(\"./language-modeling\")\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!python run_clm.py \\\n",
        "--model_type gpt2-medium \\\n",
        "--model_name_or_path gpt2-medium \\\n",
        "--train_file \"/content/train.txt\" \\\n",
        "--do_train \\\n",
        "--validation_file \"/content/test.txt\" \\\n",
        "--do_eval \\\n",
        "--per_device_train_batch_size 1 \\\n",
        "--num_train_epochs 10 \\\n",
        "--save_steps 15000 \\\n",
        "--fp16 \\\n",
        "--output_dir=\"/content/finetuned\" \\\n",
        "--overwrite_output_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.9.0+cu102)\n",
            "Collecting datasets>=1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/27/9c91ddee87b06d2de12f134c5171a49890427e398389f07f6463485723c3/datasets-1.9.0-py3-none-any.whl (262kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 7.5MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (1.1.5)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.0.12)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.70.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (21.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (1.19.5)\n",
            "Collecting fsspec>=2021.05.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/e1/7111d8afc76ee3171f4f99592cd29bac9d233ae1aa34623011506f955434/fsspec-2021.7.0-py3-none-any.whl (118kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 57.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (4.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (4.41.1)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.8.0->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.8.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.8.0->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.8.0->-r requirements.txt (line 2)) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets>=1.8.0->-r requirements.txt (line 2)) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.8.0->-r requirements.txt (line 2)) (3.5.0)\n",
            "Installing collected packages: xxhash, fsspec, datasets, sentencepiece\n",
            "Successfully installed datasets-1.9.0 fsspec-2021.7.0 sentencepiece-0.1.96 xxhash-2.0.2\n",
            "2021-07-19 16:45:21.875068: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "07/19/2021 16:45:23 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
            "07/19/2021 16:45:23 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=500,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/finetuned/runs/Jul19_16-45-23_f861b8af9330,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=10.0,\n",
            "output_dir=/content/finetuned,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=1,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=finetuned,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/finetuned,\n",
            "save_on_each_node=False,\n",
            "save_steps=15000,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "07/19/2021 16:45:24 - WARNING - datasets.builder - Using custom data configuration default-a7c55c17331e5581\n",
            "07/19/2021 16:45:24 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-a7c55c17331e5581/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
            "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-a7c55c17331e5581/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n",
            "100% 2/2 [00:00<00:00, 12035.31it/s]\n",
            "07/19/2021 16:45:24 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
            "07/19/2021 16:45:24 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
            "100% 2/2 [00:00<00:00, 1177.35it/s]\n",
            "07/19/2021 16:45:24 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "07/19/2021 16:45:24 - INFO - datasets.builder - Generating split train\n",
            "07/19/2021 16:45:24 - INFO - datasets.builder - Generating split validation\n",
            "07/19/2021 16:45:24 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-a7c55c17331e5581/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 883.48it/s]\n",
            "[INFO|file_utils.py:1624] 2021-07-19 16:45:24,778 >> https://huggingface.co/gpt2-medium/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpuj3ricu1\n",
            "Downloading: 100% 718/718 [00:00<00:00, 620kB/s]\n",
            "[INFO|file_utils.py:1628] 2021-07-19 16:45:25,072 >> storing https://huggingface.co/gpt2-medium/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|file_utils.py:1636] 2021-07-19 16:45:25,072 >> creating metadata file for /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:545] 2021-07-19 16:45:25,072 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:581] 2021-07-19 16:45:25,073 >> Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.9.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_auto.py:432] 2021-07-19 16:45:25,358 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "[INFO|configuration_utils.py:545] 2021-07-19 16:45:25,646 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:581] 2021-07-19 16:45:25,647 >> Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.9.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1624] 2021-07-19 16:45:25,931 >> https://huggingface.co/gpt2-medium/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpjf8pmy_v\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 4.13MB/s]\n",
            "[INFO|file_utils.py:1628] 2021-07-19 16:45:26,477 >> storing https://huggingface.co/gpt2-medium/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|file_utils.py:1636] 2021-07-19 16:45:26,477 >> creating metadata file for /root/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|file_utils.py:1624] 2021-07-19 16:45:26,760 >> https://huggingface.co/gpt2-medium/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmptf3op995\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 3.43MB/s]\n",
            "[INFO|file_utils.py:1628] 2021-07-19 16:45:27,184 >> storing https://huggingface.co/gpt2-medium/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|file_utils.py:1636] 2021-07-19 16:45:27,185 >> creating metadata file for /root/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|file_utils.py:1624] 2021-07-19 16:45:27,470 >> https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_tqg4i_x\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 5.29MB/s]\n",
            "[INFO|file_utils.py:1628] 2021-07-19 16:45:28,023 >> storing https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|file_utils.py:1636] 2021-07-19 16:45:28,024 >> creating metadata file for /root/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1722] 2021-07-19 16:45:28,879 >> loading file https://huggingface.co/gpt2-medium/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/fee58641d7a73348d842afaa337d5a7763dad32beff8d9008bb3c3c847749d6b.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "[INFO|tokenization_utils_base.py:1722] 2021-07-19 16:45:28,879 >> loading file https://huggingface.co/gpt2-medium/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/23c853a0fcfc12c7d72ad4e922068b6982665b673f6de30b4c5cbe5bd70a2236.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "[INFO|tokenization_utils_base.py:1722] 2021-07-19 16:45:28,879 >> loading file https://huggingface.co/gpt2-medium/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/8e4f9a65085b1b4ae69ffac9a953a44249c9ea1e72e4a7816ee87b70081df038.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "[INFO|tokenization_utils_base.py:1722] 2021-07-19 16:45:28,879 >> loading file https://huggingface.co/gpt2-medium/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1722] 2021-07-19 16:45:28,879 >> loading file https://huggingface.co/gpt2-medium/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1722] 2021-07-19 16:45:28,879 >> loading file https://huggingface.co/gpt2-medium/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|configuration_utils.py:545] 2021-07-19 16:45:29,161 >> loading configuration file https://huggingface.co/gpt2-medium/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3a7a4b7235202f93d14a4a5e8200709184c5b25a29d9cfa6b0ede5166adf0768.cf0ec4a33a38dc96108560e01338af4bd3360dd859385d451c35b41987ae73ff\n",
            "[INFO|configuration_utils.py:581] 2021-07-19 16:45:29,161 >> Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 1024,\n",
            "  \"n_head\": 16,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 24,\n",
            "  \"n_positions\": 1024,\n",
            "  \"n_special\": 0,\n",
            "  \"predict_special_tokens\": true,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.9.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1624] 2021-07-19 16:45:29,659 >> https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpitx36ir5\n",
            "Downloading: 100% 1.52G/1.52G [00:23<00:00, 65.3MB/s]\n",
            "[INFO|file_utils.py:1628] 2021-07-19 16:45:53,173 >> storing https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|file_utils.py:1636] 2021-07-19 16:45:53,173 >> creating metadata file for /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|modeling_utils.py:1271] 2021-07-19 16:45:53,174 >> loading weights file https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/6249eef5c8c1fcfccf9f36fc2e59301b109ac4036d8ebbee9c2b7f7e47f440bd.2538e2565f9e439a3668b981faf959c8b490b36dd631f3c4cd992519b2dd36f1\n",
            "[INFO|modeling_utils.py:1510] 2021-07-19 16:45:57,990 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:1519] 2021-07-19 16:45:57,990 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-medium.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Running tokenizer on dataset:   0% 0/25 [00:00<?, ?ba/s][WARNING|tokenization_utils_base.py:3243] 2021-07-19 16:45:58,560 >> Token indices sequence length is longer than the specified maximum sequence length for this model (1152 > 1024). Running this sequence through the model will result in indexing errors\n",
            "[WARNING|run_clm.py:370] 2021-07-19 16:45:58,561 >> ^^^^^^^^^^^^^^^^ Please ignore the warning above - this long input will be chunked into smaller bits before being passed to the model.\n",
            "07/19/2021 16:45:58 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-a7c55c17331e5581/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-99674946b2ccf2ab.arrow\n",
            "Running tokenizer on dataset: 100% 25/25 [00:05<00:00,  4.47ba/s]\n",
            "Running tokenizer on dataset:   0% 0/3 [00:00<?, ?ba/s]07/19/2021 16:46:03 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-a7c55c17331e5581/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-1cc4aaf6442b62a4.arrow\n",
            "Running tokenizer on dataset: 100% 3/3 [00:00<00:00,  4.19ba/s]\n",
            "Grouping texts in chunks of 1024:   0% 0/25 [00:00<?, ?ba/s]07/19/2021 16:46:05 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-a7c55c17331e5581/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-ca30c310f9e9d298.arrow\n",
            "Grouping texts in chunks of 1024: 100% 25/25 [00:34<00:00,  1.40s/ba]\n",
            "Grouping texts in chunks of 1024:   0% 0/3 [00:00<?, ?ba/s]07/19/2021 16:46:40 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-a7c55c17331e5581/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-3b33ee8d60594f98.arrow\n",
            "Grouping texts in chunks of 1024: 100% 3/3 [00:03<00:00,  1.17s/ba]\n",
            "[INFO|trainer.py:421] 2021-07-19 16:46:49,854 >> Using amp fp16 backend\n",
            "[INFO|trainer.py:1162] 2021-07-19 16:46:49,868 >> ***** Running training *****\n",
            "[INFO|trainer.py:1163] 2021-07-19 16:46:49,868 >>   Num examples = 5383\n",
            "[INFO|trainer.py:1164] 2021-07-19 16:46:49,868 >>   Num Epochs = 10\n",
            "[INFO|trainer.py:1165] 2021-07-19 16:46:49,868 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:1166] 2021-07-19 16:46:49,868 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "[INFO|trainer.py:1167] 2021-07-19 16:46:49,868 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1168] 2021-07-19 16:46:49,868 >>   Total optimization steps = 53830\n",
            "  0% 0/53830 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1308: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "{'loss': 3.2037, 'learning_rate': 4.953836150845253e-05, 'epoch': 0.09}\n",
            "{'loss': 3.166, 'learning_rate': 4.9073936466654286e-05, 'epoch': 0.19}\n",
            "{'loss': 3.1434, 'learning_rate': 4.860951142485603e-05, 'epoch': 0.28}\n",
            "{'loss': 3.1104, 'learning_rate': 4.814508638305778e-05, 'epoch': 0.37}\n",
            "{'loss': 3.0987, 'learning_rate': 4.7680661341259524e-05, 'epoch': 0.46}\n",
            "{'loss': 3.0677, 'learning_rate': 4.721623629946127e-05, 'epoch': 0.56}\n",
            "{'loss': 3.0787, 'learning_rate': 4.6751811257663017e-05, 'epoch': 0.65}\n",
            "{'loss': 3.047, 'learning_rate': 4.628738621586476e-05, 'epoch': 0.74}\n",
            "{'loss': 3.0487, 'learning_rate': 4.582389002415011e-05, 'epoch': 0.84}\n",
            "{'loss': 3.0396, 'learning_rate': 4.5359464982351854e-05, 'epoch': 0.93}\n",
            "{'loss': 2.983, 'learning_rate': 4.489596879063719e-05, 'epoch': 1.02}\n",
            "{'loss': 2.8114, 'learning_rate': 4.443154374883894e-05, 'epoch': 1.11}\n",
            "{'loss': 2.8242, 'learning_rate': 4.3967118707040685e-05, 'epoch': 1.21}\n",
            "{'loss': 2.8101, 'learning_rate': 4.350269366524243e-05, 'epoch': 1.3}\n",
            "{'loss': 2.8055, 'learning_rate': 4.303826862344418e-05, 'epoch': 1.39}\n",
            "{'loss': 2.821, 'learning_rate': 4.2573843581645924e-05, 'epoch': 1.49}\n",
            "{'loss': 2.8286, 'learning_rate': 4.210941853984767e-05, 'epoch': 1.58}\n",
            "{'loss': 2.8026, 'learning_rate': 4.1644993498049416e-05, 'epoch': 1.67}\n",
            "{'loss': 2.8078, 'learning_rate': 4.118056845625116e-05, 'epoch': 1.76}\n",
            "{'loss': 2.7948, 'learning_rate': 4.0716143414452915e-05, 'epoch': 1.86}\n",
            "{'loss': 2.8053, 'learning_rate': 4.0251718372654655e-05, 'epoch': 1.95}\n",
            "{'loss': 2.6906, 'learning_rate': 3.97872933308564e-05, 'epoch': 2.04}\n",
            "{'loss': 2.5819, 'learning_rate': 3.9323797139141746e-05, 'epoch': 2.14}\n",
            "{'loss': 2.5768, 'learning_rate': 3.8859372097343485e-05, 'epoch': 2.23}\n",
            "{'loss': 2.597, 'learning_rate': 3.839587590562883e-05, 'epoch': 2.32}\n",
            "{'loss': 2.5986, 'learning_rate': 3.7931450863830584e-05, 'epoch': 2.42}\n",
            "{'loss': 2.6172, 'learning_rate': 3.746702582203232e-05, 'epoch': 2.51}\n",
            "{'loss': 2.5917, 'learning_rate': 3.700260078023407e-05, 'epoch': 2.6}\n",
            "{'loss': 2.6019, 'learning_rate': 3.653817573843582e-05, 'epoch': 2.69}\n",
            "{'loss': 2.598, 'learning_rate': 3.607375069663756e-05, 'epoch': 2.79}\n",
            " 28% 15000/53830 [2:41:03<6:56:41,  1.55it/s][INFO|trainer.py:1917] 2021-07-19 19:27:52,982 >> Saving model checkpoint to /content/finetuned/checkpoint-15000\n",
            "[INFO|configuration_utils.py:379] 2021-07-19 19:27:52,983 >> Configuration saved in /content/finetuned/checkpoint-15000/config.json\n",
            "[INFO|modeling_utils.py:997] 2021-07-19 19:27:57,466 >> Model weights saved in /content/finetuned/checkpoint-15000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1998] 2021-07-19 19:27:57,466 >> tokenizer config file saved in /content/finetuned/checkpoint-15000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2004] 2021-07-19 19:27:57,467 >> Special tokens file saved in /content/finetuned/checkpoint-15000/special_tokens_map.json\n",
            "{'loss': 2.5893, 'learning_rate': 3.560932565483931e-05, 'epoch': 2.88}\n",
            "{'loss': 2.589, 'learning_rate': 3.514490061304106e-05, 'epoch': 2.97}\n",
            "{'loss': 2.4718, 'learning_rate': 3.468047557124281e-05, 'epoch': 3.07}\n",
            " 31% 16605/53830 [2:58:52<6:39:27,  1.55it/s]/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1308: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "{'loss': 2.41, 'learning_rate': 3.4216979379528146e-05, 'epoch': 3.16}\n",
            "{'loss': 2.3767, 'learning_rate': 3.375255433772989e-05, 'epoch': 3.25}\n",
            "{'loss': 2.3999, 'learning_rate': 3.328812929593164e-05, 'epoch': 3.34}\n",
            "{'loss': 2.4211, 'learning_rate': 3.2823704254133384e-05, 'epoch': 3.44}\n",
            "{'loss': 2.4202, 'learning_rate': 3.236020806241873e-05, 'epoch': 3.53}\n",
            "{'loss': 2.4131, 'learning_rate': 3.1895783020620476e-05, 'epoch': 3.62}\n",
            "{'loss': 2.4155, 'learning_rate': 3.1431357978822215e-05, 'epoch': 3.72}\n",
            "{'loss': 2.3968, 'learning_rate': 3.096693293702397e-05, 'epoch': 3.81}\n",
            "{'loss': 2.4189, 'learning_rate': 3.050343674530931e-05, 'epoch': 3.9}\n",
            "{'loss': 2.406, 'learning_rate': 3.0039011703511056e-05, 'epoch': 3.99}\n",
            "{'loss': 2.2482, 'learning_rate': 2.95745866617128e-05, 'epoch': 4.09}\n",
            "{'loss': 2.2432, 'learning_rate': 2.911016161991455e-05, 'epoch': 4.18}\n",
            "{'loss': 2.2532, 'learning_rate': 2.8646665428199894e-05, 'epoch': 4.27}\n",
            "{'loss': 2.2649, 'learning_rate': 2.8182240386401637e-05, 'epoch': 4.37}\n",
            "{'loss': 2.2365, 'learning_rate': 2.7717815344603383e-05, 'epoch': 4.46}\n",
            "{'loss': 2.233, 'learning_rate': 2.7253390302805126e-05, 'epoch': 4.55}\n",
            "{'loss': 2.2569, 'learning_rate': 2.6788965261006875e-05, 'epoch': 4.64}\n",
            "{'loss': 2.2609, 'learning_rate': 2.632454021920862e-05, 'epoch': 4.74}\n",
            "{'loss': 2.256, 'learning_rate': 2.5860115177410364e-05, 'epoch': 4.83}\n",
            "{'loss': 2.2553, 'learning_rate': 2.5395690135612117e-05, 'epoch': 4.92}\n",
            "{'loss': 2.1951, 'learning_rate': 2.4933122793981055e-05, 'epoch': 5.02}\n",
            "{'loss': 2.1061, 'learning_rate': 2.4468697752182798e-05, 'epoch': 5.11}\n",
            "{'loss': 2.0723, 'learning_rate': 2.4004272710384544e-05, 'epoch': 5.2}\n",
            "{'loss': 2.0796, 'learning_rate': 2.353984766858629e-05, 'epoch': 5.29}\n",
            "{'loss': 2.1206, 'learning_rate': 2.3075422626788036e-05, 'epoch': 5.39}\n",
            "{'loss': 2.1276, 'learning_rate': 2.261192643507338e-05, 'epoch': 5.48}\n",
            "{'loss': 2.1108, 'learning_rate': 2.2147501393275128e-05, 'epoch': 5.57}\n",
            " 56% 30000/53830 [5:22:38<4:15:47,  1.55it/s][INFO|trainer.py:1917] 2021-07-19 22:09:28,654 >> Saving model checkpoint to /content/finetuned/checkpoint-30000\n",
            "[INFO|configuration_utils.py:379] 2021-07-19 22:09:28,655 >> Configuration saved in /content/finetuned/checkpoint-30000/config.json\n",
            "[INFO|modeling_utils.py:997] 2021-07-19 22:09:33,211 >> Model weights saved in /content/finetuned/checkpoint-30000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1998] 2021-07-19 22:09:33,212 >> tokenizer config file saved in /content/finetuned/checkpoint-30000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2004] 2021-07-19 22:09:33,212 >> Special tokens file saved in /content/finetuned/checkpoint-30000/special_tokens_map.json\n",
            " 56% 30005/53830 [5:23:17<21:16:04,  3.21s/it]/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1308: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "{'loss': 2.1241, 'learning_rate': 2.168400520156047e-05, 'epoch': 5.67}\n",
            "{'loss': 2.1392, 'learning_rate': 2.1219580159762216e-05, 'epoch': 5.76}\n",
            "{'loss': 2.1427, 'learning_rate': 2.0755155117963962e-05, 'epoch': 5.85}\n",
            "{'loss': 2.0999, 'learning_rate': 2.0291658926249304e-05, 'epoch': 5.94}\n",
            "{'loss': 2.0637, 'learning_rate': 1.982723388445105e-05, 'epoch': 6.04}\n",
            "{'loss': 1.9977, 'learning_rate': 1.9362808842652796e-05, 'epoch': 6.13}\n",
            "{'loss': 1.98, 'learning_rate': 1.8898383800854543e-05, 'epoch': 6.22}\n",
            "{'loss': 1.9836, 'learning_rate': 1.843395875905629e-05, 'epoch': 6.32}\n",
            "{'loss': 2.0058, 'learning_rate': 1.7969533717258035e-05, 'epoch': 6.41}\n",
            "{'loss': 1.9843, 'learning_rate': 1.750510867545978e-05, 'epoch': 6.5}\n",
            "{'loss': 1.9899, 'learning_rate': 1.7040683633661527e-05, 'epoch': 6.59}\n",
            "{'loss': 2.0094, 'learning_rate': 1.6576258591863277e-05, 'epoch': 6.69}\n",
            "{'loss': 2.0092, 'learning_rate': 1.611183355006502e-05, 'epoch': 6.78}\n",
            "{'loss': 2.0013, 'learning_rate': 1.5647408508266766e-05, 'epoch': 6.87}\n",
            "{'loss': 2.0088, 'learning_rate': 1.5182983466468512e-05, 'epoch': 6.97}\n",
            "{'loss': 1.9496, 'learning_rate': 1.4719487274753854e-05, 'epoch': 7.06}\n",
            "{'loss': 1.8963, 'learning_rate': 1.4255062232955602e-05, 'epoch': 7.15}\n",
            "{'loss': 1.8895, 'learning_rate': 1.379063719115735e-05, 'epoch': 7.25}\n",
            "{'loss': 1.9075, 'learning_rate': 1.3326212149359094e-05, 'epoch': 7.34}\n",
            "{'loss': 1.9191, 'learning_rate': 1.2862715957644436e-05, 'epoch': 7.43}\n",
            "{'loss': 1.9075, 'learning_rate': 1.2398290915846184e-05, 'epoch': 7.52}\n",
            "{'loss': 1.9071, 'learning_rate': 1.193386587404793e-05, 'epoch': 7.62}\n",
            "{'loss': 1.9168, 'learning_rate': 1.1469440832249676e-05, 'epoch': 7.71}\n",
            "{'loss': 1.9142, 'learning_rate': 1.100501579045142e-05, 'epoch': 7.8}\n",
            "{'loss': 1.8864, 'learning_rate': 1.0540590748653167e-05, 'epoch': 7.9}\n",
            "{'loss': 1.9086, 'learning_rate': 1.0076165706854915e-05, 'epoch': 7.99}\n",
            "{'loss': 1.8377, 'learning_rate': 9.61174066505666e-06, 'epoch': 8.08}\n",
            "{'loss': 1.8389, 'learning_rate': 9.148244473342003e-06, 'epoch': 8.17}\n",
            "{'loss': 1.8276, 'learning_rate': 8.683819431543749e-06, 'epoch': 8.27}\n",
            "{'loss': 1.8399, 'learning_rate': 8.219394389745495e-06, 'epoch': 8.36}\n",
            " 84% 45000/53830 [8:04:15<1:34:41,  1.55it/s][INFO|trainer.py:1917] 2021-07-20 00:51:05,331 >> Saving model checkpoint to /content/finetuned/checkpoint-45000\n",
            "[INFO|configuration_utils.py:379] 2021-07-20 00:51:05,332 >> Configuration saved in /content/finetuned/checkpoint-45000/config.json\n",
            "[INFO|modeling_utils.py:997] 2021-07-20 00:51:10,242 >> Model weights saved in /content/finetuned/checkpoint-45000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1998] 2021-07-20 00:51:10,242 >> tokenizer config file saved in /content/finetuned/checkpoint-45000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2004] 2021-07-20 00:51:10,242 >> Special tokens file saved in /content/finetuned/checkpoint-45000/special_tokens_map.json\n",
            "{'loss': 1.8389, 'learning_rate': 7.754969347947241e-06, 'epoch': 8.45}\n",
            " 85% 45841/53830 [8:13:53<1:25:48,  1.55it/s]/usr/local/lib/python3.7/dist-packages/transformers/trainer.py:1308: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
            "  args.max_grad_norm,\n",
            "{'loss': 1.8308, 'learning_rate': 7.29240200631618e-06, 'epoch': 8.55}\n",
            "{'loss': 1.8329, 'learning_rate': 6.827976964517926e-06, 'epoch': 8.64}\n",
            "{'loss': 1.8351, 'learning_rate': 6.363551922719674e-06, 'epoch': 8.73}\n",
            "{'loss': 1.8573, 'learning_rate': 5.8991268809214195e-06, 'epoch': 8.82}\n",
            "{'loss': 1.8221, 'learning_rate': 5.434701839123166e-06, 'epoch': 8.92}\n",
            "{'loss': 1.8384, 'learning_rate': 4.9712056474085085e-06, 'epoch': 9.01}\n",
            "{'loss': 1.7756, 'learning_rate': 4.506780605610255e-06, 'epoch': 9.1}\n",
            "{'loss': 1.7839, 'learning_rate': 4.042355563812001e-06, 'epoch': 9.2}\n",
            "{'loss': 1.7839, 'learning_rate': 3.577930522013747e-06, 'epoch': 9.29}\n",
            "{'loss': 1.8112, 'learning_rate': 3.113505480215493e-06, 'epoch': 9.38}\n",
            "{'loss': 1.8078, 'learning_rate': 2.6490804384172397e-06, 'epoch': 9.47}\n",
            "{'loss': 1.7745, 'learning_rate': 2.184655396618986e-06, 'epoch': 9.57}\n",
            "{'loss': 1.7955, 'learning_rate': 1.720230354820732e-06, 'epoch': 9.66}\n",
            "{'loss': 1.7978, 'learning_rate': 1.2558053130224781e-06, 'epoch': 9.75}\n",
            "{'loss': 1.8062, 'learning_rate': 7.923091213078211e-07, 'epoch': 9.85}\n",
            "{'loss': 1.7702, 'learning_rate': 3.2788407950956715e-07, 'epoch': 9.94}\n",
            "100% 53830/53830 [9:39:39<00:00,  1.55it/s][INFO|trainer.py:1358] 2021-07-20 02:26:29,828 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 34779.9602, 'train_samples_per_second': 1.548, 'train_steps_per_second': 1.548, 'train_loss': 2.279561182284652, 'epoch': 10.0}\n",
            "100% 53830/53830 [9:39:39<00:00,  1.55it/s]\n",
            "[INFO|trainer.py:1917] 2021-07-20 02:26:29,830 >> Saving model checkpoint to /content/finetuned\n",
            "[INFO|configuration_utils.py:379] 2021-07-20 02:26:29,831 >> Configuration saved in /content/finetuned/config.json\n",
            "[INFO|modeling_utils.py:997] 2021-07-20 02:26:34,264 >> Model weights saved in /content/finetuned/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:1998] 2021-07-20 02:26:34,265 >> tokenizer config file saved in /content/finetuned/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2004] 2021-07-20 02:26:34,265 >> Special tokens file saved in /content/finetuned/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =       10.0\n",
            "  train_loss               =     2.2796\n",
            "  train_runtime            = 9:39:39.96\n",
            "  train_samples            =       5383\n",
            "  train_samples_per_second =      1.548\n",
            "  train_steps_per_second   =      1.548\n",
            "07/20/2021 02:26:34 - INFO - __main__ - *** Evaluate ***\n",
            "[INFO|trainer.py:2163] 2021-07-20 02:26:34,393 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2165] 2021-07-20 02:26:34,393 >>   Num examples = 597\n",
            "[INFO|trainer.py:2168] 2021-07-20 02:26:34,393 >>   Batch size = 8\n",
            "100% 75/75 [01:41<00:00,  1.35s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_loss               =     2.9073\n",
            "  eval_runtime            = 0:01:42.84\n",
            "  eval_samples            =        597\n",
            "  eval_samples_per_second =      5.805\n",
            "  eval_steps_per_second   =      0.729\n",
            "  perplexity              =     18.308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_263e693f-7f91-456b-8799-58bd23402cd6\", \"finetuned\", 4096)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvFxtUnJvjGa"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "e9fcfce950f246f593a85249c651e883",
            "a0e0a88cac084482b2b6b2031afa4b9f",
            "da823fe1262048e887bf9da6cd33fa83",
            "5b321fffc5334dddbcd21b9470c64888",
            "7fbe2e95d3de48118febb2167d0cd0fc",
            "7a14279f173044dc9b7992df8a7ea2ef",
            "38d170a30c094fb39656243f2ca6fe7c",
            "820153d5ea0f4f2c94a2d4ab84c3d56d",
            "5f92152b9b734fb8836ff598d0e60955",
            "3a083270a9464671999402f2a912792d",
            "eaf7aa7427f6481397e2047eb0f59134",
            "e65fa8512d214550905a1f3e9b53d56c",
            "802a059e1afb4de7a0b340e8b7113b05",
            "c74e4862676f47a7a1107e26990b421c",
            "8362dfde0ba64ae5814314e7e2071c3f",
            "0441fa4d7ad24067a05fafa31c4faa70",
            "acfbf4b539e74ea7817db96e3ff2933c",
            "904d584a2aaf4b9e926f5378e500dbcb",
            "ec364af0eb7d49a6b5a3a2e7fab5e46e",
            "ea2c88f73f7541519a2af6e76d21c985",
            "e5d6463870d344a3962bb47bef22bd71",
            "c423c93bc4bf487599c4867fa383f881",
            "943c15f53eb84118a6d729135611dd1f",
            "7dc9757b35724cbe84b78069976049ff",
            "e260c312835a4e81a367e942523b43d4",
            "f6e25d9d15d546d0a308e7869f843dff",
            "7e82b6ff57b147c882739c1ad880a62d",
            "ed516e174d54424898bf867f08224ee4",
            "db8480b20f8a478b82e24e0c0e0ee757",
            "677c1cf847ef481b91d2cec2528d46d6",
            "689678ee6f174b5987a99c58044956c5",
            "d9c95767980746aab5657f0ef52dfa14"
          ]
        },
        "id": "D5tYu4dvOk9v",
        "outputId": "4c546564-c1ee-489d-b276-ddb4ee81d6f1"
      },
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/Colab Notebooks/finetuned')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9fcfce950f246f593a85249c651e883",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f92152b9b734fb8836ff598d0e60955",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acfbf4b539e74ea7817db96e3ff2933c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e260c312835a4e81a367e942523b43d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKROl5YAPA5p",
        "outputId": "66d5e0f4-dc48-4a91-d6d8-b3ceabdb992b"
      },
      "source": [
        "input_sequence = \"When I was young\"\n",
        "\n",
        "input_ids = tokenizer.encode(input_sequence, return_tensors='pt')\n",
        "\n",
        "generated_text_samples = model.generate(\n",
        "    input_ids, \n",
        "    max_length=50000,\n",
        "    num_return_sequences=5,\n",
        "    no_repeat_ngram_size=2,\n",
        "    repetition_penalty=1.5,\n",
        "    top_p=0.92,\n",
        "    temperature=.85,\n",
        "    do_sample=True,\n",
        "    top_k=125,\n",
        "    early_stopping=False\n",
        ")\n",
        "\n",
        "\n",
        "with open('generated.txt', 'w') as f:\n",
        "  f.write(\"Output:\\n\" + 50 * '-' + '\\n')\n",
        "  for i, sample_output in enumerate(generated_text_samples):\n",
        "    f.write(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)) + '\\n\\n')\n",
        "\n",
        "\n",
        "print(\"Output:\\n\" + 50 * '-' + '\\n')\n",
        "for i, sample_output in enumerate(generated_text_samples):\n",
        "    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)) + '\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QA73p20yIFs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}